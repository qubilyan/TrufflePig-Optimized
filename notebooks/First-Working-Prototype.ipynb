
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import langdetect\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('posts2.pkl', 'rb') as fh:\n",
    "    data = pickle.load(fh)\n",
    "del data['block_nums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>![image](https://img.esteem.ws/wsuuxa7xk4.jpg)...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(yatsuk.kostia, dessert-home-bounty-eating-tha...</td>\n",
       "      <td>2.684</td>\n",
       "      <td>(food, food, recipe, photo, art, blog)</td>\n",
       "      <td>Dessert: home bounty. Eating that is very tasty!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#### Details\\nPadlock is an open source androi...</td>\n",
       "      <td>2018-01-15 21:03:30</td>\n",
       "      <td>(mutluhan, padlock-mobile-app-new-logo-design)</td>\n",
       "      <td>24.291</td>\n",
       "      <td>(utopian-io, utopian-io, graphics, design, log...</td>\n",
       "      <td>Padlock, Mobile App New Logo Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;center&gt;&lt;a href='https://d.tube/#!/v/greyjay26...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(greyjay265, vq01dxzf)</td>\n",
       "      <td>0.028</td>\n",
       "      <td>(dtube, dtube, bitcoin, cryptocurrency, altcoi...</td>\n",
       "      <td>LETS GET RICH. TOP 5 ALTCOINS MAY CHANGE YOUR ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body          created_at  \\\n",
       "0  ![image](https://img.esteem.ws/wsuuxa7xk4.jpg)... 2018-01-15 21:17:42   \n",
       "1  #### Details\\nPadlock is an open source androi... 2018-01-15 21:03:30   \n",
       "2  ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3  ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "4  <center><a href='https://d.tube/#!/v/greyjay26... 2018-01-15 21:17:51   \n",
       "\n",
       "                                                post  reward  \\\n",
       "0  (yatsuk.kostia, dessert-home-bounty-eating-tha...   2.684   \n",
       "1     (mutluhan, padlock-mobile-app-new-logo-design)  24.291   \n",
       "2          (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3  (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "4                             (greyjay265, vq01dxzf)   0.028   \n",
       "\n",
       "                                                tags  \\\n",
       "0             (food, food, recipe, photo, art, blog)   \n",
       "1  (utopian-io, utopian-io, graphics, design, log...   \n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "4  (dtube, dtube, bitcoin, cryptocurrency, altcoi...   \n",
       "\n",
       "                                               title  \n",
       "0   Dessert: home bounty. Eating that is very tasty!  \n",
       "1                Padlock, Mobile App New Logo Design  \n",
       "2                  \"Get a Skill not Qualifications \"  \n",
       "3  Getting Over(Story) Part 4: Blind and Disillus...  \n",
       "4  LETS GET RICH. TOP 5 ALTCOINS MAY CHANGE YOUR ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_df = pd.DataFrame(data)\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lookat , yes , and '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_images_and_links(text):\n",
    "    return re.sub('!?\\[[-a-zA-Z0-9?@: %._\\+~#=/()]*\\]\\([-a-zA-Z0-9?@:%._\\+~#=/()]+\\)', '', text)\n",
    "\n",
    "filter_images_and_links('Lookat ![j kjds](wehwjrkjewrk.de), yes [iii](jlkajddjsla), and '\n",
    "                        '![images (17).jpg](https://steemitimages.com/DQmQF5BxHtPdPu1yKipV67GpnRdzemPpEFCqB59kVXC6Ahy/images%20(17).jpg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_html_tags(text):\n",
    "    return re.sub('</?[a-z]{1,11}>', '', text)\n",
    "\n",
    "filter_html_tags('<jkdjdksakd>hi</img>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I like '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_urls(text):\n",
    "    return re.sub('(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]'\n",
    "                   '[a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.'\n",
    "                   '[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}'\n",
    "                   '|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]'\n",
    "                   '{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})', '', text)\n",
    "\n",
    "filter_urls('I like www.pipes.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi \\n\\n\\t!!!.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_special_characters(text):\n",
    "    return re.sub('[^A-Za-z0-9\\s;,.?!]+', '', text)\n",
    "\n",
    "filter_special_characters('Hi//)(&(/%( \\n\\n\\t)))\"\"\"\"\"\"!!!.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi hey     kk'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_formatting(text):\n",
    "    text = re.sub('&?nbsp', ' ',text)\n",
    "    text = re.sub('aligncenter', '', text)\n",
    "    text = re.sub('styletextalign', '', text)\n",
    "    return text\n",
    "\n",
    "filter_formatting('Hi&nbsphey aligncenter nbsp styletextalign kk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_paragraphs(text):\n",
    "    return text.count('\\n\\n') + 1\n",
    "\n",
    "count_paragraphs('Hello \\n\\n World \\n\\n\\n !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi ee'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_newlines(text):\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "replace_newlines('Hi \\n\\n\\tee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering images\n",
      "Filtering html\n",
      "Filtering urls\n",
      "Filtering formatting\n",
      "Filtering special characters\n",
      "Counting paragraphs\n",
      "Calculating length\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>![image](https://img.esteem.ws/wsuuxa7xk4.jpg)...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(yatsuk.kostia, dessert-home-bounty-eating-tha...</td>\n",
       "      <td>2.684</td>\n",
       "      <td>(food, food, recipe, photo, art, blog)</td>\n",
       "      <td>Dessert: home bounty. Eating that is very tasty!</td>\n",
       "      <td>\\n\\nFor cooking we need\\nChocolate 200 gr\\nBut...</td>\n",
       "      <td>4</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#### Details\\nPadlock is an open source androi...</td>\n",
       "      <td>2018-01-15 21:03:30</td>\n",
       "      <td>(mutluhan, padlock-mobile-app-new-logo-design)</td>\n",
       "      <td>24.291</td>\n",
       "      <td>(utopian-io, utopian-io, graphics, design, log...</td>\n",
       "      <td>Padlock, Mobile App New Logo Design</td>\n",
       "      <td>Details\\nPadlock is an open source androidios...</td>\n",
       "      <td>22</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;center&gt;&lt;a href='https://d.tube/#!/v/greyjay26...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(greyjay265, vq01dxzf)</td>\n",
       "      <td>0.028</td>\n",
       "      <td>(dtube, dtube, bitcoin, cryptocurrency, altcoi...</td>\n",
       "      <td>LETS GET RICH. TOP 5 ALTCOINS MAY CHANGE YOUR ...</td>\n",
       "      <td>a href src\\n\\nJoin our Discord \\n\\nInstagram \\...</td>\n",
       "      <td>10</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body          created_at  \\\n",
       "0  ![image](https://img.esteem.ws/wsuuxa7xk4.jpg)... 2018-01-15 21:17:42   \n",
       "1  #### Details\\nPadlock is an open source androi... 2018-01-15 21:03:30   \n",
       "2  ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3  ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "4  <center><a href='https://d.tube/#!/v/greyjay26... 2018-01-15 21:17:51   \n",
       "\n",
       "                                                post  reward  \\\n",
       "0  (yatsuk.kostia, dessert-home-bounty-eating-tha...   2.684   \n",
       "1     (mutluhan, padlock-mobile-app-new-logo-design)  24.291   \n",
       "2          (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3  (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "4                             (greyjay265, vq01dxzf)   0.028   \n",
       "\n",
       "                                                tags  \\\n",
       "0             (food, food, recipe, photo, art, blog)   \n",
       "1  (utopian-io, utopian-io, graphics, design, log...   \n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "4  (dtube, dtube, bitcoin, cryptocurrency, altcoi...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Dessert: home bounty. Eating that is very tasty!   \n",
       "1                Padlock, Mobile App New Logo Design   \n",
       "2                  \"Get a Skill not Qualifications \"   \n",
       "3  Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "4  LETS GET RICH. TOP 5 ALTCOINS MAY CHANGE YOUR ...   \n",
       "\n",
       "                                       filtered_body  paragraphs  length  \n",
       "0  \\n\\nFor cooking we need\\nChocolate 200 gr\\nBut...           4     592  \n",
       "1   Details\\nPadlock is an open source androidios...          22     858  \n",
       "2  \\nLast month I was part of the interview panel...          13    6452  \n",
       "3  \\nLove oh love, sweet like wine made from fres...           5    2488  \n",
       "4  a href src\\n\\nJoin our Discord \\n\\nInstagram \\...          10     292  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Filtering images')\n",
    "post_df['filtered_body'] = post_df.body.apply(lambda x: filter_images_and_links(x))\n",
    "print('Filtering html')\n",
    "post_df['filtered_body'] = post_df.filtered_body.apply(lambda x: filter_html_tags(x))\n",
    "print('Filtering urls')\n",
    "post_df['filtered_body'] = post_df.filtered_body.apply(lambda x: filter_urls(x))\n",
    "print('Filtering formatting')\n",
    "post_df['filtered_body'] = post_df.filtered_body.apply(lambda x: filter_formatting(x))\n",
    "print('Filtering special characters')\n",
    "post_df['filtered_body'] = post_df.filtered_body.apply(lambda x: filter_special_characters(x))\n",
    "print('Counting paragraphs')\n",
    "post_df['paragraphs'] = post_df.filtered_body.apply(lambda x: count_paragraphs(x))\n",
    "print('Calculating length')\n",
    "post_df['length'] = post_df.filtered_body.apply(lambda x: len(x))\n",
    "\n",
    "post_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 19518 large enough posts out of 38103\n"
     ]
    }
   ],
   "source": [
    "large_post_df = post_df.loc[post_df.length >= 1000, :]\n",
    "print('Keeping {} large enough posts out of {}'.format(len(large_post_df), len(post_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text, max_length=5000):\n",
    "    try:\n",
    "        return langdetect.detect(text[:max_length])\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "detect_language('die katze ist klein der hund auch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting language\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "print('Detecting language')\n",
    "large_post_df.loc[:, 'language'] = large_post_df.filtered_body.apply(lambda x: detect_language(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15540 English posts\n"
     ]
    }
   ],
   "source": [
    "en_df = large_post_df.loc[large_post_df.language == 'en', :]\n",
    "print('Found {} English posts'.format(len(en_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi my name is!', 'Slim Shady!', 'Really?', 'Yeah.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps = \"([A-Z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"Taken from https://stackoverflow.com/questions/4576077/python-split-text-on-sentences\"\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + caps + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(caps + \"[.]\" + caps + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + caps + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences\n",
    "    \n",
    "split_into_sentences('Hi my name is! Slim Shady! Really? Yeah.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_average_sentence_length(text_list):\n",
    "    return np.mean([len(x) for x in text_list])\n",
    "\n",
    "compute_average_sentence_length(['huhuh.', 'sbbbasdsads'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_sentence_length_variance(text_list):\n",
    "    return np.var([len(x) for x in text_list])\n",
    "\n",
    "compute_sentence_length_variance(['huhuh.', 'sbbbasdsads', 'jj djdjd', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing average sentence length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3194: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sentence length variance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "      <th>language</th>\n",
       "      <th>filtered_sentences</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>sentence_length_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "      <td>en</td>\n",
       "      <td>[Last month I was part of the interview panel ...</td>\n",
       "      <td>47.522388</td>\n",
       "      <td>5803.995767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "      <td>en</td>\n",
       "      <td>[Love oh love, sweet like wine made from fresh...</td>\n",
       "      <td>129.736842</td>\n",
       "      <td>5953.141274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>2018-01-15 21:15:09</td>\n",
       "      <td>(modemser, neo-is-like-the-neo-in-matrix-man)</td>\n",
       "      <td>33.189</td>\n",
       "      <td>(kr, kr, steemit, cryptocurrency, money, crypto)</td>\n",
       "      <td>Neo is like  Neo in Matrix</td>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>en</td>\n",
       "      <td>[When everyone was sealing Neo after the ICO  ...</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>5791.910035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>![](https://steemitimages.com/DQmZL4fFGuEnrT2v...</td>\n",
       "      <td>2018-01-15 21:18:00</td>\n",
       "      <td>(mbadayee, does-buddhism-hold-a-pessimistic-view)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(art, art, photo, beauty, stach, busy)</td>\n",
       "      <td>Does Buddhism Hold A Pessimistic View?</td>\n",
       "      <td>\\nAdditionally, note that using allcolumn or d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "      <td>en</td>\n",
       "      <td>[Additionally, note that using allcolumn or di...</td>\n",
       "      <td>95.153846</td>\n",
       "      <td>3541.899408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mermaid: - The evidence of the mermaid is foun...</td>\n",
       "      <td>2018-01-11 17:45:51</td>\n",
       "      <td>(nitinaryan, the-real-mermaid-feabaa3eae2d)</td>\n",
       "      <td>0.552</td>\n",
       "      <td>(mermaid, mermaid, tech, fish)</td>\n",
       "      <td>the real mermaid</td>\n",
       "      <td>mermaid  The evidence of the mermaid is found ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1569</td>\n",
       "      <td>en</td>\n",
       "      <td>[mermaid  The evidence of the mermaid is found...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>939.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body          created_at  \\\n",
       "2   ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3   ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "5   When everyone was sealing Neo after the ICO  b... 2018-01-15 21:15:09   \n",
       "7   ![](https://steemitimages.com/DQmZL4fFGuEnrT2v... 2018-01-15 21:18:00   \n",
       "10  mermaid: - The evidence of the mermaid is foun... 2018-01-11 17:45:51   \n",
       "\n",
       "                                                 post  reward  \\\n",
       "2           (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3   (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "5       (modemser, neo-is-like-the-neo-in-matrix-man)  33.189   \n",
       "7   (mbadayee, does-buddhism-hold-a-pessimistic-view)   0.000   \n",
       "10        (nitinaryan, the-real-mermaid-feabaa3eae2d)   0.552   \n",
       "\n",
       "                                                tags  \\\n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "5   (kr, kr, steemit, cryptocurrency, money, crypto)   \n",
       "7             (art, art, photo, beauty, stach, busy)   \n",
       "10                    (mermaid, mermaid, tech, fish)   \n",
       "\n",
       "                                                title  \\\n",
       "2                   \"Get a Skill not Qualifications \"   \n",
       "3   Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "5                          Neo is like  Neo in Matrix   \n",
       "7              Does Buddhism Hold A Pessimistic View?   \n",
       "10                                   the real mermaid   \n",
       "\n",
       "                                        filtered_body  paragraphs  length  \\\n",
       "2   \\nLast month I was part of the interview panel...          13    6452   \n",
       "3   \\nLove oh love, sweet like wine made from fres...           5    2488   \n",
       "5   When everyone was sealing Neo after the ICO  b...           5    1408   \n",
       "7   \\nAdditionally, note that using allcolumn or d...           5    5003   \n",
       "10  mermaid  The evidence of the mermaid is found ...           3    1569   \n",
       "\n",
       "   language                                 filtered_sentences  \\\n",
       "2        en  [Last month I was part of the interview panel ...   \n",
       "3        en  [Love oh love, sweet like wine made from fresh...   \n",
       "5        en  [When everyone was sealing Neo after the ICO  ...   \n",
       "7        en  [Additionally, note that using allcolumn or di...   \n",
       "10       en  [mermaid  The evidence of the mermaid is found...   \n",
       "\n",
       "    average_sentence_length  sentence_length_variance  \n",
       "2                 47.522388               5803.995767  \n",
       "3                129.736842               5953.141274  \n",
       "5                 80.176471               5791.910035  \n",
       "7                 95.153846               3541.899408  \n",
       "10                64.000000                939.043478  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Splitting into sentences')\n",
    "en_df['filtered_sentences'] = en_df.filtered_body.apply(lambda x: split_into_sentences(x))\n",
    "print('Computing average sentence length')\n",
    "en_df['average_sentence_length'] =  \\\n",
    "    en_df.filtered_sentences.apply(lambda x: compute_average_sentence_length(x))\n",
    "print('Computing sentence length variance')\n",
    "en_df['sentence_length_variance'] =  \\\n",
    "    en_df.filtered_sentences.apply(lambda x: compute_sentence_length_variance(x))\n",
    "\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_body_and_title(df):\n",
    "    return df.title.apply(lambda x: x.lower()) +' ' + df.filtered_body.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi my name is yolok'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_punctuation(text):\n",
    "    return re.sub('[;,.?!]+', '', text)\n",
    "\n",
    "filter_punctuation('hi. my. name. is yolo!;;k;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining Body and Title\n",
      "Filtering special characters again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering punctuation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing new lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "      <th>language</th>\n",
       "      <th>filtered_sentences</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>sentence_length_variance</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "      <td>en</td>\n",
       "      <td>[Last month I was part of the interview panel ...</td>\n",
       "      <td>47.522388</td>\n",
       "      <td>5803.995767</td>\n",
       "      <td>get a skill not qualifications last month i wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "      <td>en</td>\n",
       "      <td>[Love oh love, sweet like wine made from fresh...</td>\n",
       "      <td>129.736842</td>\n",
       "      <td>5953.141274</td>\n",
       "      <td>getting overstory part 4 blind and disillusion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>2018-01-15 21:15:09</td>\n",
       "      <td>(modemser, neo-is-like-the-neo-in-matrix-man)</td>\n",
       "      <td>33.189</td>\n",
       "      <td>(kr, kr, steemit, cryptocurrency, money, crypto)</td>\n",
       "      <td>Neo is like  Neo in Matrix</td>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>en</td>\n",
       "      <td>[When everyone was sealing Neo after the ICO  ...</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>5791.910035</td>\n",
       "      <td>neo is like neo in matrix when everyone was se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>![](https://steemitimages.com/DQmZL4fFGuEnrT2v...</td>\n",
       "      <td>2018-01-15 21:18:00</td>\n",
       "      <td>(mbadayee, does-buddhism-hold-a-pessimistic-view)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(art, art, photo, beauty, stach, busy)</td>\n",
       "      <td>Does Buddhism Hold A Pessimistic View?</td>\n",
       "      <td>\\nAdditionally, note that using allcolumn or d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "      <td>en</td>\n",
       "      <td>[Additionally, note that using allcolumn or di...</td>\n",
       "      <td>95.153846</td>\n",
       "      <td>3541.899408</td>\n",
       "      <td>does buddhism hold a pessimistic view addition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mermaid: - The evidence of the mermaid is foun...</td>\n",
       "      <td>2018-01-11 17:45:51</td>\n",
       "      <td>(nitinaryan, the-real-mermaid-feabaa3eae2d)</td>\n",
       "      <td>0.552</td>\n",
       "      <td>(mermaid, mermaid, tech, fish)</td>\n",
       "      <td>the real mermaid</td>\n",
       "      <td>mermaid  The evidence of the mermaid is found ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1569</td>\n",
       "      <td>en</td>\n",
       "      <td>[mermaid  The evidence of the mermaid is found...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>939.043478</td>\n",
       "      <td>the real mermaid mermaid the evidence of the m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body          created_at  \\\n",
       "2   ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3   ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "5   When everyone was sealing Neo after the ICO  b... 2018-01-15 21:15:09   \n",
       "7   ![](https://steemitimages.com/DQmZL4fFGuEnrT2v... 2018-01-15 21:18:00   \n",
       "10  mermaid: - The evidence of the mermaid is foun... 2018-01-11 17:45:51   \n",
       "\n",
       "                                                 post  reward  \\\n",
       "2           (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3   (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "5       (modemser, neo-is-like-the-neo-in-matrix-man)  33.189   \n",
       "7   (mbadayee, does-buddhism-hold-a-pessimistic-view)   0.000   \n",
       "10        (nitinaryan, the-real-mermaid-feabaa3eae2d)   0.552   \n",
       "\n",
       "                                                tags  \\\n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "5   (kr, kr, steemit, cryptocurrency, money, crypto)   \n",
       "7             (art, art, photo, beauty, stach, busy)   \n",
       "10                    (mermaid, mermaid, tech, fish)   \n",
       "\n",
       "                                                title  \\\n",
       "2                   \"Get a Skill not Qualifications \"   \n",
       "3   Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "5                          Neo is like  Neo in Matrix   \n",
       "7              Does Buddhism Hold A Pessimistic View?   \n",
       "10                                   the real mermaid   \n",
       "\n",
       "                                        filtered_body  paragraphs  length  \\\n",
       "2   \\nLast month I was part of the interview panel...          13    6452   \n",
       "3   \\nLove oh love, sweet like wine made from fres...           5    2488   \n",
       "5   When everyone was sealing Neo after the ICO  b...           5    1408   \n",
       "7   \\nAdditionally, note that using allcolumn or d...           5    5003   \n",
       "10  mermaid  The evidence of the mermaid is found ...           3    1569   \n",
       "\n",
       "   language                                 filtered_sentences  \\\n",
       "2        en  [Last month I was part of the interview panel ...   \n",
       "3        en  [Love oh love, sweet like wine made from fresh...   \n",
       "5        en  [When everyone was sealing Neo after the ICO  ...   \n",
       "7        en  [Additionally, note that using allcolumn or di...   \n",
       "10       en  [mermaid  The evidence of the mermaid is found...   \n",
       "\n",
       "    average_sentence_length  sentence_length_variance  \\\n",
       "2                 47.522388               5803.995767   \n",
       "3                129.736842               5953.141274   \n",
       "5                 80.176471               5791.910035   \n",
       "7                 95.153846               3541.899408   \n",
       "10                64.000000                939.043478   \n",
       "\n",
       "                                             combined  \n",
       "2   get a skill not qualifications last month i wa...  \n",
       "3   getting overstory part 4 blind and disillusion...  \n",
       "5   neo is like neo in matrix when everyone was se...  \n",
       "7   does buddhism hold a pessimistic view addition...  \n",
       "10  the real mermaid mermaid the evidence of the m...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Combining Body and Title')\n",
    "en_df['combined'] = combine_body_and_title(en_df)\n",
    "print('Filtering special characters again')\n",
    "en_df['combined'] = en_df.combined.apply(lambda x: filter_special_characters(x))\n",
    "print('Filtering punctuation')\n",
    "en_df['combined'] = en_df.combined.apply(lambda x: filter_punctuation(x))\n",
    "\n",
    "print('Replacing new lines')\n",
    "en_df['combined'] = en_df.combined.apply(lambda x: replace_newlines(x))\n",
    "\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker = SpellChecker('en_US')\n",
    "def count_mistakes(text):\n",
    "    checker.set_text(text)\n",
    "    nerrors = len([x for x in checker])\n",
    "    return nerrors\n",
    "\n",
    "count_mistakes('hi hiw are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spell checking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print('Spell checking')\n",
    "en_df['spelling_errors'] = en_df.combined.apply(lambda x: count_mistakes(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/robert/anaconda3/envs/steemit/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "      <th>language</th>\n",
       "      <th>filtered_sentences</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>sentence_length_variance</th>\n",
       "      <th>combined</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "      <td>en</td>\n",
       "      <td>[Last month I was part of the interview panel ...</td>\n",
       "      <td>47.522388</td>\n",
       "      <td>5803.995767</td>\n",
       "      <td>get a skill not qualifications last month i wa...</td>\n",
       "      <td>60</td>\n",
       "      <td>[get, a, skill, not, qualifications, last, mon...</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "      <td>en</td>\n",
       "      <td>[Love oh love, sweet like wine made from fresh...</td>\n",
       "      <td>129.736842</td>\n",
       "      <td>5953.141274</td>\n",
       "      <td>getting overstory part 4 blind and disillusion...</td>\n",
       "      <td>13</td>\n",
       "      <td>[getting, overstory, part, 4, blind, and, disi...</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>2018-01-15 21:15:09</td>\n",
       "      <td>(modemser, neo-is-like-the-neo-in-matrix-man)</td>\n",
       "      <td>33.189</td>\n",
       "      <td>(kr, kr, steemit, cryptocurrency, money, crypto)</td>\n",
       "      <td>Neo is like  Neo in Matrix</td>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>en</td>\n",
       "      <td>[When everyone was sealing Neo after the ICO  ...</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>5791.910035</td>\n",
       "      <td>neo is like neo in matrix when everyone was se...</td>\n",
       "      <td>83</td>\n",
       "      <td>[neo, is, like, neo, in, matrix, when, everyon...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>![](https://steemitimages.com/DQmZL4fFGuEnrT2v...</td>\n",
       "      <td>2018-01-15 21:18:00</td>\n",
       "      <td>(mbadayee, does-buddhism-hold-a-pessimistic-view)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(art, art, photo, beauty, stach, busy)</td>\n",
       "      <td>Does Buddhism Hold A Pessimistic View?</td>\n",
       "      <td>\\nAdditionally, note that using allcolumn or d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "      <td>en</td>\n",
       "      <td>[Additionally, note that using allcolumn or di...</td>\n",
       "      <td>95.153846</td>\n",
       "      <td>3541.899408</td>\n",
       "      <td>does buddhism hold a pessimistic view addition...</td>\n",
       "      <td>19</td>\n",
       "      <td>[does, buddhism, hold, a, pessimistic, view, a...</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mermaid: - The evidence of the mermaid is foun...</td>\n",
       "      <td>2018-01-11 17:45:51</td>\n",
       "      <td>(nitinaryan, the-real-mermaid-feabaa3eae2d)</td>\n",
       "      <td>0.552</td>\n",
       "      <td>(mermaid, mermaid, tech, fish)</td>\n",
       "      <td>the real mermaid</td>\n",
       "      <td>mermaid  The evidence of the mermaid is found ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1569</td>\n",
       "      <td>en</td>\n",
       "      <td>[mermaid  The evidence of the mermaid is found...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>939.043478</td>\n",
       "      <td>the real mermaid mermaid the evidence of the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>[the, real, mermaid, mermaid, the, evidence, o...</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body          created_at  \\\n",
       "2   ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3   ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "5   When everyone was sealing Neo after the ICO  b... 2018-01-15 21:15:09   \n",
       "7   ![](https://steemitimages.com/DQmZL4fFGuEnrT2v... 2018-01-15 21:18:00   \n",
       "10  mermaid: - The evidence of the mermaid is foun... 2018-01-11 17:45:51   \n",
       "\n",
       "                                                 post  reward  \\\n",
       "2           (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3   (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "5       (modemser, neo-is-like-the-neo-in-matrix-man)  33.189   \n",
       "7   (mbadayee, does-buddhism-hold-a-pessimistic-view)   0.000   \n",
       "10        (nitinaryan, the-real-mermaid-feabaa3eae2d)   0.552   \n",
       "\n",
       "                                                tags  \\\n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "5   (kr, kr, steemit, cryptocurrency, money, crypto)   \n",
       "7             (art, art, photo, beauty, stach, busy)   \n",
       "10                    (mermaid, mermaid, tech, fish)   \n",
       "\n",
       "                                                title  \\\n",
       "2                   \"Get a Skill not Qualifications \"   \n",
       "3   Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "5                          Neo is like  Neo in Matrix   \n",
       "7              Does Buddhism Hold A Pessimistic View?   \n",
       "10                                   the real mermaid   \n",
       "\n",
       "                                        filtered_body  paragraphs  length  \\\n",
       "2   \\nLast month I was part of the interview panel...          13    6452   \n",
       "3   \\nLove oh love, sweet like wine made from fres...           5    2488   \n",
       "5   When everyone was sealing Neo after the ICO  b...           5    1408   \n",
       "7   \\nAdditionally, note that using allcolumn or d...           5    5003   \n",
       "10  mermaid  The evidence of the mermaid is found ...           3    1569   \n",
       "\n",
       "   language                                 filtered_sentences  \\\n",
       "2        en  [Last month I was part of the interview panel ...   \n",
       "3        en  [Love oh love, sweet like wine made from fresh...   \n",
       "5        en  [When everyone was sealing Neo after the ICO  ...   \n",
       "7        en  [Additionally, note that using allcolumn or di...   \n",
       "10       en  [mermaid  The evidence of the mermaid is found...   \n",
       "\n",
       "    average_sentence_length  sentence_length_variance  \\\n",
       "2                 47.522388               5803.995767   \n",
       "3                129.736842               5953.141274   \n",
       "5                 80.176471               5791.910035   \n",
       "7                 95.153846               3541.899408   \n",
       "10                64.000000                939.043478   \n",
       "\n",
       "                                             combined  spelling_errors  \\\n",
       "2   get a skill not qualifications last month i wa...               60   \n",
       "3   getting overstory part 4 blind and disillusion...               13   \n",
       "5   neo is like neo in matrix when everyone was se...               83   \n",
       "7   does buddhism hold a pessimistic view addition...               19   \n",
       "10  the real mermaid mermaid the evidence of the m...                7   \n",
       "\n",
       "                                               tokens  num_words  \n",
       "2   [get, a, skill, not, qualifications, last, mon...       1154  \n",
       "3   [getting, overstory, part, 4, blind, and, disi...        488  \n",
       "5   [neo, is, like, neo, in, matrix, when, everyon...        219  \n",
       "7   [does, buddhism, hold, a, pessimistic, view, a...        857  \n",
       "10  [the, real, mermaid, mermaid, the, evidence, o...        295  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tokenization')\n",
    "en_df['tokens'] = en_df.combined.apply(lambda x: x.split(' '))\n",
    "en_df['num_words'] = en_df.tokens.apply(lambda x: len(x))\n",
    "\n",
    "en_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data set has 15498 entries\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "      <th>language</th>\n",
       "      <th>filtered_sentences</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>sentence_length_variance</th>\n",
       "      <th>combined</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "      <td>en</td>\n",
       "      <td>[Last month I was part of the interview panel ...</td>\n",
       "      <td>47.522388</td>\n",
       "      <td>5803.995767</td>\n",
       "      <td>get a skill not qualifications last month i wa...</td>\n",
       "      <td>60</td>\n",
       "      <td>[get, a, skill, not, qualifications, last, mon...</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "      <td>en</td>\n",
       "      <td>[Love oh love, sweet like wine made from fresh...</td>\n",
       "      <td>129.736842</td>\n",
       "      <td>5953.141274</td>\n",
       "      <td>getting overstory part 4 blind and disillusion...</td>\n",
       "      <td>13</td>\n",
       "      <td>[getting, overstory, part, 4, blind, and, disi...</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>2018-01-15 21:15:09</td>\n",
       "      <td>(modemser, neo-is-like-the-neo-in-matrix-man)</td>\n",
       "      <td>33.189</td>\n",
       "      <td>(kr, kr, steemit, cryptocurrency, money, crypto)</td>\n",
       "      <td>Neo is like  Neo in Matrix</td>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>en</td>\n",
       "      <td>[When everyone was sealing Neo after the ICO  ...</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>5791.910035</td>\n",
       "      <td>neo is like neo in matrix when everyone was se...</td>\n",
       "      <td>83</td>\n",
       "      <td>[neo, is, like, neo, in, matrix, when, everyon...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>![](https://steemitimages.com/DQmZL4fFGuEnrT2v...</td>\n",
       "      <td>2018-01-15 21:18:00</td>\n",
       "      <td>(mbadayee, does-buddhism-hold-a-pessimistic-view)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(art, art, photo, beauty, stach, busy)</td>\n",
       "      <td>Does Buddhism Hold A Pessimistic View?</td>\n",
       "      <td>\\nAdditionally, note that using allcolumn or d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "      <td>en</td>\n",
       "      <td>[Additionally, note that using allcolumn or di...</td>\n",
       "      <td>95.153846</td>\n",
       "      <td>3541.899408</td>\n",
       "      <td>does buddhism hold a pessimistic view addition...</td>\n",
       "      <td>19</td>\n",
       "      <td>[does, buddhism, hold, a, pessimistic, view, a...</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mermaid: - The evidence of the mermaid is foun...</td>\n",
       "      <td>2018-01-11 17:45:51</td>\n",
       "      <td>(nitinaryan, the-real-mermaid-feabaa3eae2d)</td>\n",
       "      <td>0.552</td>\n",
       "      <td>(mermaid, mermaid, tech, fish)</td>\n",
       "      <td>the real mermaid</td>\n",
       "      <td>mermaid  The evidence of the mermaid is found ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1569</td>\n",
       "      <td>en</td>\n",
       "      <td>[mermaid  The evidence of the mermaid is found...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>939.043478</td>\n",
       "      <td>the real mermaid mermaid the evidence of the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>[the, real, mermaid, mermaid, the, evidence, o...</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body          created_at  \\\n",
       "2   ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3   ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "5   When everyone was sealing Neo after the ICO  b... 2018-01-15 21:15:09   \n",
       "7   ![](https://steemitimages.com/DQmZL4fFGuEnrT2v... 2018-01-15 21:18:00   \n",
       "10  mermaid: - The evidence of the mermaid is foun... 2018-01-11 17:45:51   \n",
       "\n",
       "                                                 post  reward  \\\n",
       "2           (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3   (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "5       (modemser, neo-is-like-the-neo-in-matrix-man)  33.189   \n",
       "7   (mbadayee, does-buddhism-hold-a-pessimistic-view)   0.000   \n",
       "10        (nitinaryan, the-real-mermaid-feabaa3eae2d)   0.552   \n",
       "\n",
       "                                                tags  \\\n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "5   (kr, kr, steemit, cryptocurrency, money, crypto)   \n",
       "7             (art, art, photo, beauty, stach, busy)   \n",
       "10                    (mermaid, mermaid, tech, fish)   \n",
       "\n",
       "                                                title  \\\n",
       "2                   \"Get a Skill not Qualifications \"   \n",
       "3   Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "5                          Neo is like  Neo in Matrix   \n",
       "7              Does Buddhism Hold A Pessimistic View?   \n",
       "10                                   the real mermaid   \n",
       "\n",
       "                                        filtered_body  paragraphs  length  \\\n",
       "2   \\nLast month I was part of the interview panel...          13    6452   \n",
       "3   \\nLove oh love, sweet like wine made from fres...           5    2488   \n",
       "5   When everyone was sealing Neo after the ICO  b...           5    1408   \n",
       "7   \\nAdditionally, note that using allcolumn or d...           5    5003   \n",
       "10  mermaid  The evidence of the mermaid is found ...           3    1569   \n",
       "\n",
       "   language                                 filtered_sentences  \\\n",
       "2        en  [Last month I was part of the interview panel ...   \n",
       "3        en  [Love oh love, sweet like wine made from fresh...   \n",
       "5        en  [When everyone was sealing Neo after the ICO  ...   \n",
       "7        en  [Additionally, note that using allcolumn or di...   \n",
       "10       en  [mermaid  The evidence of the mermaid is found...   \n",
       "\n",
       "    average_sentence_length  sentence_length_variance  \\\n",
       "2                 47.522388               5803.995767   \n",
       "3                129.736842               5953.141274   \n",
       "5                 80.176471               5791.910035   \n",
       "7                 95.153846               3541.899408   \n",
       "10                64.000000                939.043478   \n",
       "\n",
       "                                             combined  spelling_errors  \\\n",
       "2   get a skill not qualifications last month i wa...               60   \n",
       "3   getting overstory part 4 blind and disillusion...               13   \n",
       "5   neo is like neo in matrix when everyone was se...               83   \n",
       "7   does buddhism hold a pessimistic view addition...               19   \n",
       "10  the real mermaid mermaid the evidence of the m...                7   \n",
       "\n",
       "                                               tokens  num_words  \n",
       "2   [get, a, skill, not, qualifications, last, mon...       1154  \n",
       "3   [getting, overstory, part, 4, blind, and, disi...        488  \n",
       "5   [neo, is, like, neo, in, matrix, when, everyon...        219  \n",
       "7   [does, buddhism, hold, a, pessimistic, view, a...        857  \n",
       "10  [the, real, mermaid, mermaid, the, evidence, o...        295  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = en_df.dropna()\n",
    "\n",
    "print('Final data set has {} entries'.format(len(final_df)))\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.lsimodel import LsiModel\n",
    "from gensim import corpora\n",
    "from gensim.matutils import corpus2dense\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>post</th>\n",
       "      <th>reward</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>filtered_body</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>length</th>\n",
       "      <th>language</th>\n",
       "      <th>filtered_sentences</th>\n",
       "      <th>average_sentence_length</th>\n",
       "      <th>sentence_length_variance</th>\n",
       "      <th>combined</th>\n",
       "      <th>spelling_errors</th>\n",
       "      <th>tokens</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>![31050144-interior-of-busy-architect-s-office...</td>\n",
       "      <td>2018-01-15 21:17:42</td>\n",
       "      <td>(ankunda, get-a-skill-not-qualifications)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(get, get, a, skill, not, qualifications)</td>\n",
       "      <td>\"Get a Skill not Qualifications \"</td>\n",
       "      <td>\\nLast month I was part of the interview panel...</td>\n",
       "      <td>13</td>\n",
       "      <td>6452</td>\n",
       "      <td>en</td>\n",
       "      <td>[Last month I was part of the interview panel ...</td>\n",
       "      <td>47.522388</td>\n",
       "      <td>5803.995767</td>\n",
       "      <td>get a skill not qualifications last month i wa...</td>\n",
       "      <td>60</td>\n",
       "      <td>[get, a, skill, not, qualifications, last, mon...</td>\n",
       "      <td>1154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>![images (17).jpg](https://steemitimages.com/D...</td>\n",
       "      <td>2018-01-15 21:17:51</td>\n",
       "      <td>(belemo, getting-over-story-part-4-blind-and-d...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(stach, stach, story, love, writing, blog)</td>\n",
       "      <td>Getting Over(Story) Part 4: Blind and Disillus...</td>\n",
       "      <td>\\nLove oh love, sweet like wine made from fres...</td>\n",
       "      <td>5</td>\n",
       "      <td>2488</td>\n",
       "      <td>en</td>\n",
       "      <td>[Love oh love, sweet like wine made from fresh...</td>\n",
       "      <td>129.736842</td>\n",
       "      <td>5953.141274</td>\n",
       "      <td>getting overstory part 4 blind and disillusion...</td>\n",
       "      <td>13</td>\n",
       "      <td>[getting, overstory, part, 4, blind, and, disi...</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>2018-01-15 21:15:09</td>\n",
       "      <td>(modemser, neo-is-like-the-neo-in-matrix-man)</td>\n",
       "      <td>33.189</td>\n",
       "      <td>(kr, kr, steemit, cryptocurrency, money, crypto)</td>\n",
       "      <td>Neo is like  Neo in Matrix</td>\n",
       "      <td>When everyone was sealing Neo after the ICO  b...</td>\n",
       "      <td>5</td>\n",
       "      <td>1408</td>\n",
       "      <td>en</td>\n",
       "      <td>[When everyone was sealing Neo after the ICO  ...</td>\n",
       "      <td>80.176471</td>\n",
       "      <td>5791.910035</td>\n",
       "      <td>neo is like neo in matrix when everyone was se...</td>\n",
       "      <td>83</td>\n",
       "      <td>[neo, is, like, neo, in, matrix, when, everyon...</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>![](https://steemitimages.com/DQmZL4fFGuEnrT2v...</td>\n",
       "      <td>2018-01-15 21:18:00</td>\n",
       "      <td>(mbadayee, does-buddhism-hold-a-pessimistic-view)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>(art, art, photo, beauty, stach, busy)</td>\n",
       "      <td>Does Buddhism Hold A Pessimistic View?</td>\n",
       "      <td>\\nAdditionally, note that using allcolumn or d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5003</td>\n",
       "      <td>en</td>\n",
       "      <td>[Additionally, note that using allcolumn or di...</td>\n",
       "      <td>95.153846</td>\n",
       "      <td>3541.899408</td>\n",
       "      <td>does buddhism hold a pessimistic view addition...</td>\n",
       "      <td>19</td>\n",
       "      <td>[does, buddhism, hold, a, pessimistic, view, a...</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mermaid: - The evidence of the mermaid is foun...</td>\n",
       "      <td>2018-01-11 17:45:51</td>\n",
       "      <td>(nitinaryan, the-real-mermaid-feabaa3eae2d)</td>\n",
       "      <td>0.552</td>\n",
       "      <td>(mermaid, mermaid, tech, fish)</td>\n",
       "      <td>the real mermaid</td>\n",
       "      <td>mermaid  The evidence of the mermaid is found ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1569</td>\n",
       "      <td>en</td>\n",
       "      <td>[mermaid  The evidence of the mermaid is found...</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>939.043478</td>\n",
       "      <td>the real mermaid mermaid the evidence of the m...</td>\n",
       "      <td>7</td>\n",
       "      <td>[the, real, mermaid, mermaid, the, evidence, o...</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body          created_at  \\\n",
       "2   ![31050144-interior-of-busy-architect-s-office... 2018-01-15 21:17:42   \n",
       "3   ![images (17).jpg](https://steemitimages.com/D... 2018-01-15 21:17:51   \n",
       "5   When everyone was sealing Neo after the ICO  b... 2018-01-15 21:15:09   \n",
       "7   ![](https://steemitimages.com/DQmZL4fFGuEnrT2v... 2018-01-15 21:18:00   \n",
       "10  mermaid: - The evidence of the mermaid is foun... 2018-01-11 17:45:51   \n",
       "\n",
       "                                                 post  reward  \\\n",
       "2           (ankunda, get-a-skill-not-qualifications)   0.000   \n",
       "3   (belemo, getting-over-story-part-4-blind-and-d...   0.000   \n",
       "5       (modemser, neo-is-like-the-neo-in-matrix-man)  33.189   \n",
       "7   (mbadayee, does-buddhism-hold-a-pessimistic-view)   0.000   \n",
       "10        (nitinaryan, the-real-mermaid-feabaa3eae2d)   0.552   \n",
       "\n",
       "                                                tags  \\\n",
       "2          (get, get, a, skill, not, qualifications)   \n",
       "3         (stach, stach, story, love, writing, blog)   \n",
       "5   (kr, kr, steemit, cryptocurrency, money, crypto)   \n",
       "7             (art, art, photo, beauty, stach, busy)   \n",
       "10                    (mermaid, mermaid, tech, fish)   \n",
       "\n",
       "                                                title  \\\n",
       "2                   \"Get a Skill not Qualifications \"   \n",
       "3   Getting Over(Story) Part 4: Blind and Disillus...   \n",
       "5                          Neo is like  Neo in Matrix   \n",
       "7              Does Buddhism Hold A Pessimistic View?   \n",
       "10                                   the real mermaid   \n",
       "\n",
       "                                        filtered_body  paragraphs  length  \\\n",
       "2   \\nLast month I was part of the interview panel...          13    6452   \n",
       "3   \\nLove oh love, sweet like wine made from fres...           5    2488   \n",
       "5   When everyone was sealing Neo after the ICO  b...           5    1408   \n",
       "7   \\nAdditionally, note that using allcolumn or d...           5    5003   \n",
       "10  mermaid  The evidence of the mermaid is found ...           3    1569   \n",
       "\n",
       "   language                                 filtered_sentences  \\\n",
       "2        en  [Last month I was part of the interview panel ...   \n",
       "3        en  [Love oh love, sweet like wine made from fresh...   \n",
       "5        en  [When everyone was sealing Neo after the ICO  ...   \n",
       "7        en  [Additionally, note that using allcolumn or di...   \n",
       "10       en  [mermaid  The evidence of the mermaid is found...   \n",
       "\n",
       "    average_sentence_length  sentence_length_variance  \\\n",
       "2                 47.522388               5803.995767   \n",
       "3                129.736842               5953.141274   \n",
       "5                 80.176471               5791.910035   \n",
       "7                 95.153846               3541.899408   \n",
       "10                64.000000                939.043478   \n",
       "\n",
       "                                             combined  spelling_errors  \\\n",
       "2   get a skill not qualifications last month i wa...               60   \n",
       "3   getting overstory part 4 blind and disillusion...               13   \n",
       "5   neo is like neo in matrix when everyone was se...               83   \n",
       "7   does buddhism hold a pessimistic view addition...               19   \n",
       "10  the real mermaid mermaid the evidence of the m...                7   \n",
       "\n",
       "                                               tokens  num_words  \n",
       "2   [get, a, skill, not, qualifications, last, mon...       1154  \n",
       "3   [getting, overstory, part, 4, blind, and, disi...        488  \n",
       "5   [neo, is, like, neo, in, matrix, when, everyon...        219  \n",
       "7   [does, buddhism, hold, a, pessimistic, view, a...        857  \n",
       "10  [the, real, mermaid, mermaid, the, evidence, o...        295  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "train_mask = np.random.rand(len(final_df)) < 0.8\n",
    "test_mask = ~train_mask\n",
    "train_df = final_df.loc[train_mask]\n",
    "test_df = final_df.loc[test_mask]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = train_df.tokens\n",
    "test_tokens = test_df.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering extremes of dict with length 171584\n",
      "New size of dictionary 31358\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(train_tokens)\n",
    "print('Filtering extremes of dict with length {}'.format(len(dictionary)))\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.33)\n",
    "print('New size of dictionary {}'.format(len(dictionary)))\n",
    "train_corpus = [dictionary.doc2bow(text) for text in train_tokens]\n",
    "test_corpus = [dictionary.doc2bow(text) for text in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 100\n",
    "lsi = LsiModel(train_corpus, num_topics=NUM_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_projection = lsi[train_corpus]\n",
    "test_projection = lsi[test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_X_data(lsiprojection, body_length, paragraphs, num_words, spelling_mistakes, \n",
    "                  average_sentence_length, sentence_length_variance):\n",
    "    ntopics = len(lsiprojection[1])\n",
    "    X = np.zeros((len(body_length), ntopics + 9))\n",
    "    X[:, 0:ntopics]  = corpus2dense(lsiprojection, len(lsiprojection[1])).T\n",
    "    X[:, -1] = body_length\n",
    "    X[:, -2] = paragraphs\n",
    "    X[:, -3] = num_words\n",
    "    X[:, -4] = spelling_mistakes\n",
    "    X[:, -5] = body_length / num_words\n",
    "    X[:, -6] = num_words / paragraphs\n",
    "    X[:, -7] = spelling_mistakes / num_words\n",
    "    X[:, -8] = average_sentence_length\n",
    "    X[:, -9] = sentence_length_variance\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9.69344199e-01,  1.87147255e+01,  5.17872667e+00, ...,\n",
       "          1.15400000e+03,  1.30000000e+01,  6.45200000e+03],\n",
       "        [ 1.34267777e-01,  1.49811735e+01,  1.05465183e+01, ...,\n",
       "          4.88000000e+02,  5.00000000e+00,  2.48800000e+03],\n",
       "        [ 3.12234104e-01,  2.30090618e+00, -8.54095399e-01, ...,\n",
       "          2.19000000e+02,  5.00000000e+00,  1.40800000e+03],\n",
       "        ...,\n",
       "        [ 1.57745445e+00,  6.12002945e+00, -2.23980713e+00, ...,\n",
       "          5.85000000e+02,  1.20000000e+01,  3.48600000e+03],\n",
       "        [ 2.05192709e+00,  8.18592262e+00, -1.88543167e+01, ...,\n",
       "          4.18000000e+02,  1.60000000e+01,  3.42500000e+03],\n",
       "        [ 6.12906516e-02,  2.26315665e+00, -1.06722474e+00, ...,\n",
       "          3.89000000e+02,  2.60000000e+01,  2.49500000e+03]]),\n",
       " array([ 0.   ,  0.   , 33.189, ...,  0.214,  0.   , 22.22 ]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = combine_X_data(train_projection, train_df.length, \n",
    "                   train_df.paragraphs, train_df.num_words, train_df.spelling_errors,\n",
    "                  train_df.average_sentence_length, train_df.sentence_length_variance)\n",
    "y = train_df.reward.values.astype(float)\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2.27268729e-02,  1.18526721e+00, -8.80281627e-02, ...,\n",
       "          2.35000000e+02,  7.00000000e+00,  1.30500000e+03],\n",
       "        [ 4.59578447e-02,  2.64207602e+00,  2.10098922e-02, ...,\n",
       "          3.28000000e+02,  6.00000000e+00,  1.76600000e+03],\n",
       "        [ 5.39351851e-02,  2.05534744e+00, -1.81949794e+00, ...,\n",
       "          2.04000000e+02,  5.00000000e+00,  1.07600000e+03],\n",
       "        ...,\n",
       "        [ 5.24931327e-02,  2.05785799e+00, -1.33078313e+00, ...,\n",
       "          1.81000000e+02,  7.00000000e+00,  1.09100000e+03],\n",
       "        [ 1.12479019e+00,  6.10666885e+01,  3.02878799e+01, ...,\n",
       "          1.88500000e+03,  4.80000000e+01,  1.01830000e+04],\n",
       "        [ 3.00360203e+00,  1.20533241e+02,  3.38389931e+01, ...,\n",
       "          9.67200000e+03,  9.00000000e+00,  5.67710000e+04]]),\n",
       " array([0.00000e+00, 9.79000e-01, 1.30000e+00, ..., 9.34000e-01,\n",
       "        5.70322e+02, 3.20000e-02]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = combine_X_data(test_projection, test_df.length, test_df.paragraphs,\n",
    "                       test_df.num_words, test_df.spelling_errors,\n",
    "                       test_df.average_sentence_length, test_df.sentence_length_variance)\n",
    "y_test = test_df.reward.values.astype(float)\n",